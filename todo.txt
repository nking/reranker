-- if need to reduce training time,
   consider pre-tokenizing the data
   and loading that instead.
   - realtime inference would still need to tokenize
     the data dynamically
