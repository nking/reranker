-- if need to reduce training time,
   consider pre-tokenizing the data
   and loading that instead.
   - realtime inference would still need to tokenize
     the data dynamically

-- low priority: 
   consider exploring ordinal regression w/ sequence-to-sequence
